stage_1:
  target: stage1.RAE
  params:
    encoder_cls: 'SigLIP2wNorm'
    encoder_config_path: 'google/siglip2-base-patch16-256'
    encoder_input_size: 256
    encoder_params:
      model_name: 'google/siglip2-base-patch16-256'
      num_tokens: 256
    decoder_config_path: 'configs/decoder/ViTXL'
    pretrained_decoder_path: 'models/decoders/siglip2/base_p16_i256/ViTXL_n08/model.pt'
    noise_tau: 0.
    reshape_to_2d: true
    normalization_stat_path: 'models/stats/siglip2/base_p16_i256/imagenet1k/stat.pt'

stage_2:
  target: stage2.models.DDT.DiTwDDTHead
  params:
    input_size: 16
    patch_size: 1
    in_channels: 768
    hidden_size: [1152, 2048]
    depth: [28, 2]
    num_heads: [16, 16]
    mlp_ratio: 4.0
    class_dropout_prob: 0.1
    num_classes: 1000
    use_qknorm: false
    use_swiglu: true
    use_rope: true
    use_rmsnorm: true
    wo_shift: false
    use_pos_embed: true
  ckpt: 'models/DiTs/SigLIP2/base_p16_i256/ImageNet256/DiTDH-XL/stage2_model.pt'

transport:
  params:
    path_type: 'Linear'
    prediction: 'velocity'
    time_dist_type: 'uniform'

sampler:
  mode: ODE
  params:
    sampling_method: 'euler'
    num_steps: 50
    atol: 1e-6
    rtol: 1e-3
    reverse: false

guidance:
  method: 'cfg'
  scale: 1.0
  t-min: 0.0
  t-max: 1.0

misc:
  latent_size: [768, 16, 16]
  num_classes: 1000
  time_dist_shift_dim: 196608
  time_dist_shift_base: 4096